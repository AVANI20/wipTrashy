{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xX3FM-nqgbSQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, models, transforms\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from wiptrashymodules.dummydataloader import load_data, split_train_val_test\n",
    "from wiptrashymodules.dummyviz import show_confusion_mat, imshow, create_grid_for_mb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KnJvyPRWgbWc"
   },
   "outputs": [],
   "source": [
    "class VGG(object):\n",
    "\n",
    "    def __init__(self, pretrained_model, device, num_classes=25, lr=0.0001, reg=0.0, dtype=np.float32, mode=\"ft_extract\"):\n",
    "        self.params = {}\n",
    "        self.reg = reg\n",
    "        self.dtype = dtype \n",
    "        self.model = pretrained_model\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.device = device\n",
    "        self.save_model_path = '../wipTrashy/trainedModel_VGG19.pt'\n",
    "\n",
    "        self.set_parameter_requires_grad(mode)\n",
    "        num_features = self.model.classifier[6].in_features\n",
    "        features = list(self.model.classifier.children())[:-1]                  \n",
    "        features.extend([nn.Linear(num_features, num_classes).to(self.device)]) \n",
    "        self.model.classifier = nn.Sequential(*features)            \n",
    "                            \n",
    "    def set_parameter_requires_grad(self, mode):\n",
    "        if mode == \"ft_extract\":\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif mode == \"finetune_last\":\n",
    "            for param in self.model.features[:19].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "                \n",
    "    def gather_optimizable_params(self):\n",
    "        params_to_optimize = []\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_optimize.append(param)\n",
    "\n",
    "        return params_to_optimize\n",
    "\n",
    "    \n",
    "    def train(self, dataloaders, dataset_sizes, num_epochs):\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        params_to_optimize = self.gather_optimizable_params()\n",
    "        optimizer = optim.Adam(params_to_optimize, lr = self.lr)\n",
    "        exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "        for epoch in tqdm(range(0, num_epochs)):\n",
    "            print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
    "            print('-'*10)\n",
    "            \n",
    "            for mode in ['train', 'val']:\n",
    "                if mode == \"train\":\n",
    "                    exp_lr_scheduler.step()\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval() \n",
    "                    \n",
    "                total_loss = 0.0\n",
    "                total_correct = 0 \n",
    "\n",
    "                for inputs, labels in dataloaders[mode]:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(mode == 'train'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        _, y_preds = torch.max(outputs, 1)\n",
    "\n",
    "                        loss = self.loss_fn(outputs, labels)\n",
    "                \n",
    "                        if mode == \"train\":\n",
    "                            loss.backward() \n",
    "                            optimizer.step()\n",
    "                \n",
    "                    total_loss += loss.item() * inputs.size(0)\n",
    "                    total_correct += torch.sum(y_preds == labels.data)\n",
    "                \n",
    "                epoch_loss = total_loss / dataset_sizes[mode]\n",
    "                epoch_acc = total_correct.double() / dataset_sizes[mode]\n",
    "\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(mode, epoch_loss, epoch_acc))\n",
    "            \n",
    "                if mode == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "                    torch.save(self.model.state_dict(), self.save_model_path)\n",
    "                    \n",
    "            print()\n",
    "\n",
    "        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "\n",
    "        torch.save(self.model.state_dict(), self.save_model_path)\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "\n",
    "\n",
    "    def eval_model(self, dataloaders, mode = 'val'):\n",
    "        since = time.time()\n",
    "        avg_loss, avg_acc, total_loss, total_correct = 0,0,0,0\n",
    "        num_batches = len(dataloaders[mode])\n",
    "        mode_str = \"Validation\" if mode == 'val' else \"Test\"\n",
    "        \n",
    "        print(\"Evaluating model on {} set\".format(mode_str))\n",
    "        print('-' * 10)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloaders[mode]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\r{} batch {}/{}\".format(mode_str, i, num_batches), end='', flush=True)\n",
    "                \n",
    "                self.model.train(False)\n",
    "                self.model.eval()\n",
    "\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                \n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                total_correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "        avg_loss = total_loss / dataset_sizes[mode]\n",
    "        avg_acc = total_correct.double() / dataset_sizes[mode]\n",
    "            \n",
    "        elapsed_time = time.time() - since\n",
    "        print()\n",
    "        print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Average {} loss     : {:.4f}\".format(mode_str, avg_loss))\n",
    "        print(\"Average {} accuracy : {:.4f}\".format(mode_str, avg_acc))\n",
    "        print('-' * 10)\n",
    "\n",
    "                \n",
    "                \n",
    "    def load_model(self, path, train_mode = False):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        if train_mode == False:\n",
    "            self.model.eval()\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def visualize_model(self, dataloaders, num_images=16):\n",
    "        self.model.train(False)\n",
    "        self.model.eval()\n",
    "        \n",
    "        images_so_far = 0\n",
    "        file_path_base = '../wipTrashy/'\n",
    "        confusion_matrix = torch.zeros(self.num_classes, self.num_classes)\n",
    "                                                   \n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloaders['test']):\n",
    "                inputs, labels = data\n",
    "                size = inputs.size()[0]\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = self.model(inputs)                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "                    \n",
    "                create_grid_for_mb(i, inputs, num_images, class_names, preds, labels, file_path_base)\n",
    "        show_confusion_mat(confusion_matrix, self.num_classes, class_names, outfile=file_path_base + \"confusion_matrix_vgg19.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiptrashymodules.dummydataloader import load_data, split_train_val_test\n",
    "split_train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qnLbcN7qgbZB"
   },
   "outputs": [],
   "source": [
    "pathname = '../wipTrashy/trashyTrainTestVal'\n",
    "dataloaders, dataset_sizes, class_names = load_data(pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2zhM8t3Igbbj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avani\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\avani\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg19 = models.vgg19(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "88A6JmbUgbdy"
   },
   "outputs": [],
   "source": [
    "vgg_model = VGG(vgg19, device, num_classes=25, mode=\"finetune_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.load_model('../wipTrashy/trainedModel_VGG19.pt', train_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iEU4pkwNgbgR",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]C:\\Users\\avani\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.9621 Acc: 0.7323\n",
      "val Loss: 0.4025 Acc: 0.8863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                        | 1/20 [1:05:26<20:43:28, 3926.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.6147 Acc: 0.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 2/20 [2:08:34<19:13:28, 3844.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4356 Acc: 0.8669\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 0.8388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▍                                                                | 3/20 [3:06:56<17:24:59, 3688.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4221 Acc: 0.8848\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.5595 Acc: 0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 4/20 [4:05:02<16:02:19, 3608.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4437 Acc: 0.8722\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 0.8621\n",
      "val Loss: 0.3511 Acc: 0.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████                                                         | 5/20 [5:03:14<14:51:34, 3566.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.4486 Acc: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 6/20 [6:01:33<13:46:47, 3543.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3955 Acc: 0.8877\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3102 Acc: 0.9068\n",
      "val Loss: 0.2524 Acc: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▌                                                 | 7/20 [7:00:23<12:46:50, 3539.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.2656 Acc: 0.9260\n",
      "val Loss: 0.2444 Acc: 0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 8/20 [7:59:10<11:47:02, 3535.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.2509 Acc: 0.9287\n",
      "val Loss: 0.2287 Acc: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▏                                         | 9/20 [8:58:07<10:48:14, 3535.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.2295 Acc: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████                                      | 10/20 [9:57:00<9:49:10, 3535.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2401 Acc: 0.9361\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.2338 Acc: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▎                                 | 11/20 [10:56:02<8:50:32, 3537.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2408 Acc: 0.9355\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.2203 Acc: 0.9361\n",
      "val Loss: 0.2303 Acc: 0.9388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████                              | 12/20 [11:54:36<7:50:41, 3530.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.2276 Acc: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████▊                          | 13/20 [12:53:25<6:51:47, 3529.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2384 Acc: 0.9386\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▌                      | 14/20 [13:52:17<5:53:03, 3530.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2340 Acc: 0.9380\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9416\n",
      "val Loss: 0.2317 Acc: 0.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▎                  | 15/20 [14:50:50<4:53:45, 3525.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.2028 Acc: 0.9408\n",
      "val Loss: 0.2310 Acc: 0.9396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████               | 16/20 [15:49:28<3:54:52, 3523.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9426\n",
      "val Loss: 0.2286 Acc: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▊           | 17/20 [16:48:16<2:56:13, 3524.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.1901 Acc: 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████▌       | 18/20 [17:47:45<1:57:55, 3537.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2313 Acc: 0.9407\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 19/20 [18:46:10<58:48, 3528.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2305 Acc: 0.9407\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.1992 Acc: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 20/20 [19:45:14<00:00, 3555.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2305 Acc: 0.9398\n",
      "\n",
      "Best val Acc: 0.941699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.train(dataloaders, dataset_sizes, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aaVbvW6Wgbi8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.load_model('../wipTrashy/trainedModel_VGG19.pt', train_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH7C90yygblQ"
   },
   "outputs": [],
   "source": [
    "vgg_model.visualize_model(dataloaders, num_images=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q1KxufdCgbnj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on Validation set\n",
      "----------\n",
      "Validation batch 0/76\n",
      "Evaluation completed in 9m 9s\n",
      "Average Validation loss     : 0.2286\n",
      "Average Validation accuracy : 0.9417\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "vgg_model.eval_model(dataloaders, mode = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wz3Lc865gb50"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG-19 model for TrashBox dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
